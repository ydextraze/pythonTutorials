{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description\n",
    "\n",
    "A dataset containing the prices and other attributes of almost 54,000 diamonds. The variables are as follows:\n",
    "\n",
    "#### Details\n",
    "\n",
    "* carat. weight of the diamond (0.2--5.01)\n",
    "* cut. quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n",
    "* colour. diamond colour, from J (worst) to D (best)\n",
    "* clarity. a measurement of how clear the diamond is (I1 (worst), SI1, SI2, VS1, VS2, VVS1, VVS2, IF (best))\n",
    "* depth. total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43--79)\n",
    "* table. width of top of diamond relative to widest point (43--95)\n",
    "* price. price in US dollars (\\$326--\\$18,823)\n",
    "* x. length in mm (0--10.74)\n",
    "* y. width in mm (0--58.9)\n",
    "* z. depth in mm (0--31.8)\n",
    "\n",
    "Read here for more information :\n",
    "\n",
    "https://www.brilliance.com/education/diamonds/cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "%config InlineBackend.figure_format = 'png' #set 'png' here when working on notebook\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load the file and set the first column as the index\n",
    "train = pd.read_csv(r\"C:\\Users\\piush\\Desktop\\Dataset\\Assignment 1\\diamonds.csv\",index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53936</th>\n",
       "      <td>0.72</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>60.8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.76</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53937</th>\n",
       "      <td>0.72</td>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>63.1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53938</th>\n",
       "      <td>0.70</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.66</td>\n",
       "      <td>5.68</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53939</th>\n",
       "      <td>0.86</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.12</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53940</th>\n",
       "      <td>0.75</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.83</td>\n",
       "      <td>5.87</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat        cut color clarity  depth  table  price     x     y     z\n",
       "53936   0.72      Ideal     D     SI1   60.8   57.0   2757  5.75  5.76  3.50\n",
       "53937   0.72       Good     D     SI1   63.1   55.0   2757  5.69  5.75  3.61\n",
       "53938   0.70  Very Good     D     SI1   62.8   60.0   2757  5.66  5.68  3.56\n",
       "53939   0.86    Premium     H     SI2   61.0   58.0   2757  6.15  6.12  3.74\n",
       "53940   0.75      Ideal     D     SI2   62.2   55.0   2757  5.83  5.87  3.64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------\n",
      "TRAIN SET INFORMATION\n",
      "---------------------\n",
      "Shape of training set: (53940, 10) \n",
      "\n",
      "Column Headers: ['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y', 'z'] \n",
      "\n",
      "carat      float64\n",
      "cut         object\n",
      "color       object\n",
      "clarity     object\n",
      "depth      float64\n",
      "table      float64\n",
      "price        int64\n",
      "x          float64\n",
      "y          float64\n",
      "z          float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n\\n---------------------\")\n",
    "print (\"TRAIN SET INFORMATION\")\n",
    "print (\"---------------------\")\n",
    "print (\"Shape of training set:\", train.shape, \"\\n\")\n",
    "print (\"Column Headers:\", list(train.columns.values), \"\\n\")\n",
    "print (train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 53940 number of observations and 10 different variables.\n",
    "\n",
    "*** The different kind of variables are :\n",
    "    *** 'carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y', 'z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SET INFORMATION\n",
      "========================\n",
      "\n",
      "'carat' has 273 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "[ 0.23  0.21  0.29  0.31  0.24  0.26  0.22  0.3   0.2   0.32]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'cut' has 5 unique values\n",
      "['Ideal' 'Premium' 'Good' 'Very Good' 'Fair']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'color' has 7 unique values\n",
      "['E' 'I' 'J' 'H' 'F' 'G' 'D']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'clarity' has 8 unique values\n",
      "['SI2' 'SI1' 'VS1' 'VS2' 'VVS2' 'VVS1' 'I1' 'IF']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'depth' has 184 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "[ 61.5  59.8  56.9  62.4  63.3  62.8  62.3  61.9  65.1  59.4]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'table' has 127 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "[ 55.  61.  65.  58.  57.  56.  54.  62.  59.  63.]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'price' has 11602 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "[326 327 334 335 336 337 338 339 340 342]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'x' has 554 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "[ 3.95  3.89  4.05  4.2   4.34  3.94  4.07  3.87  4.    4.25]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'y' has 552 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "[ 3.98  3.84  4.07  4.23  4.35  3.96  4.11  3.78  4.05  4.28]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'z' has 375 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "[ 2.43  2.31  2.63  2.75  2.48  2.47  2.53  2.49  2.39  2.73]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Features with missing values:\n",
      "[]\n",
      "\n",
      "\n",
      "Features with non-numeric values:\n",
      "['cut', 'color', 'clarity']\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "missing_values = []\n",
    "nonumeric_values = []\n",
    "\n",
    "print (\"TRAINING SET INFORMATION\")\n",
    "print (\"========================\\n\")\n",
    "\n",
    "for column in train:\n",
    "    # Find all the unique feature values\n",
    "    uniq = train[column].unique()\n",
    "    print (\"'{}' has {} unique values\" .format(column,uniq.size))\n",
    "    if (uniq.size > 10):\n",
    "        print(\"~~Listing up to 10 unique values~~\")\n",
    "    print (uniq[0:10])\n",
    "    print (\"\\n-----------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    # Find features with missing values\n",
    "    if (True in pd.isnull(uniq)):\n",
    "        s = \"{} has {} missing\" .format(column, pd.isnull(train[column]).sum())\n",
    "        missing_values.append(s)\n",
    "    \n",
    "    # Find features with non-numeric values\n",
    "    for i in range (1, np.prod(uniq.shape)):\n",
    "        if (re.match('nan', str(uniq[i]))):\n",
    "            break\n",
    "        if not (re.search('(^\\d+\\.?\\d*$)|(^\\d*\\.?\\d+$)', str(uniq[i]))):\n",
    "            nonumeric_values.append(column)\n",
    "            break\n",
    "  \n",
    "print (\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n",
    "print (\"Features with missing values:\\n{}\\n\\n\" .format(missing_values))\n",
    "print (\"Features with non-numeric values:\\n{}\" .format(nonumeric_values))\n",
    "print (\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no missing value\n",
    "\n",
    "It has 3 categorical variables:\n",
    "* cut, color and clarity\n",
    "    \n",
    "cut is ordinal variable\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicate IDs for 53940 total entries\n"
     ]
    }
   ],
   "source": [
    "#check for duplicates\n",
    "# Check for duplicates\n",
    "idsUnique = len(set(train.index))\n",
    "idsTotal = train.shape[0]\n",
    "idsDupli = idsTotal - idsUnique\n",
    "print(\"There are \" + str(idsDupli) + \" duplicate IDs for \" + str(idsTotal) + \" total entries\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.797940</td>\n",
       "      <td>61.749405</td>\n",
       "      <td>57.457184</td>\n",
       "      <td>3932.799722</td>\n",
       "      <td>5.731157</td>\n",
       "      <td>5.734526</td>\n",
       "      <td>3.538734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.474011</td>\n",
       "      <td>1.432621</td>\n",
       "      <td>2.234491</td>\n",
       "      <td>3989.439738</td>\n",
       "      <td>1.121761</td>\n",
       "      <td>1.142135</td>\n",
       "      <td>0.705699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>2.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2401.000000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>3.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.040000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>5324.250000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>4.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.010000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>18823.000000</td>\n",
       "      <td>10.740000</td>\n",
       "      <td>58.900000</td>\n",
       "      <td>31.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              carat         depth         table         price             x  \\\n",
       "count  53940.000000  53940.000000  53940.000000  53940.000000  53940.000000   \n",
       "mean       0.797940     61.749405     57.457184   3932.799722      5.731157   \n",
       "std        0.474011      1.432621      2.234491   3989.439738      1.121761   \n",
       "min        0.200000     43.000000     43.000000    326.000000      0.000000   \n",
       "25%        0.400000     61.000000     56.000000    950.000000      4.710000   \n",
       "50%        0.700000     61.800000     57.000000   2401.000000      5.700000   \n",
       "75%        1.040000     62.500000     59.000000   5324.250000      6.540000   \n",
       "max        5.010000     79.000000     95.000000  18823.000000     10.740000   \n",
       "\n",
       "                  y             z  \n",
       "count  53940.000000  53940.000000  \n",
       "mean       5.734526      3.538734  \n",
       "std        1.142135      0.705699  \n",
       "min        0.000000      0.000000  \n",
       "25%        4.720000      2.910000  \n",
       "50%        5.710000      3.530000  \n",
       "75%        6.540000      4.040000  \n",
       "max       58.900000     31.800000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get summary of numerical variables\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can get an idea of a possible skew in the data by comparing the mean to the median, i.e. the 50% figure.\n",
    "\n",
    "It looks that Price is skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For the non-numerical values, we can look at frequency distribution to understand whether they make sense or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ideal        21551\n",
       "Premium      13791\n",
       "Very Good    12082\n",
       "Good          4906\n",
       "Fair          1610\n",
       "Name: cut, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['cut'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G    11292\n",
       "E     9797\n",
       "F     9542\n",
       "H     8304\n",
       "D     6775\n",
       "I     5422\n",
       "J     2808\n",
       "Name: color, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['color'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SI1     13065\n",
       "VS2     12258\n",
       "SI2      9194\n",
       "VS1      8171\n",
       "VVS2     5066\n",
       "VVS1     3655\n",
       "IF       1790\n",
       "I1        741\n",
       "Name: clarity, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['clarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carat    1.116646\n",
      "depth   -0.082294\n",
      "table    0.796896\n",
      "price    1.618395\n",
      "x        0.378676\n",
      "y        2.434167\n",
      "z        1.522423\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Skewness of the distribution\n",
    "\n",
    "print(train.skew())\n",
    "\n",
    "# Values close to 0 show less skew\n",
    "# The attributes are not skewed too much. Some algos may benefit if skew is corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cut\n",
       "Fair          1610\n",
       "Good          4906\n",
       "Ideal        21551\n",
       "Premium      13791\n",
       "Very Good    12082\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of instances belonging to each class\n",
    "\n",
    "train.groupby('cut').size()\n",
    "\n",
    "#Need to study more--- We see that all classes have an equal presence. No class re-balancing is necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#re column the dataset with price at the end .. as a target\n",
    "train_copy  = train[['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'x', 'y', 'z','price']]\n",
    "# We will visualize all the attributes using Violin Plot - a combination of box and density plots\n",
    "\n",
    "#names of all the attributes \n",
    "cols = train_copy.columns\n",
    "\n",
    "#number of attributes (exclude target)\n",
    "size = len(cols)-1\n",
    "\n",
    "#x-axis has target attribute to distinguish between classes\n",
    "x = cols[size]\n",
    "\n",
    "#y-axis shows values of an attribute\n",
    "y = cols[0:size]\n",
    "\n",
    "#Plot violin for all attributes\n",
    "for i in range(0,size):\n",
    "    sns.violinplot(data=train_copy,x=x,y=y[i])  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check when a value in a column is zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df[(df['A']>0) & (df['B']>0) & (df['C']>0)].count()\n",
    "\n",
    "train[(train['x'] == 0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[(train['y'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Separate Categorical Variables\n",
    "cats = []\n",
    "for col in train.columns.values:\n",
    "    if train[col].dtype == 'object':\n",
    "        cats.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create separte datasets for Continuous vs Categorical\n",
    "\n",
    "train_cont = train.drop(cats, axis=1)\n",
    "train_cat = train[cats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_cont.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_cat.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting univariate distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#draw a histogram and not fit a kernel density estimate (KDE).\n",
    "sns.distplot(train['carat'], kde = True, color = 'b', hist_kws={'alpha': 0.9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (6.0, 3.0)\n",
    "prices = pd.DataFrame({\"price\":train[\"price\"], \"log(price + 1)\":np.log1p(train[\"price\"])})\n",
    "prices.hist(bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (6.0, 3.0)\n",
    "carat = pd.DataFrame({\"carat\":train[\"carat\"], \"log(carat + 1)\":np.log1p(train[\"carat\"])})\n",
    "carat.hist(bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.plot(np.log1p(train[\"carat\"]), np.log1p(train[\"price\"]), linestyle='--',label='log(price + 1)')\n",
    "#plt.plot(train['YrSold'], train['SalePrice'],  label='Year Sold')\n",
    "plt.xlabel('log(carat + 1)')\n",
    "plt.ylabel('log(price + 1)')\n",
    "plt.title('log(carat + 1) Vs log(price + 1)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(train['carat'], kde = True, color = 'b', hist_kws={'alpha': 0.9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(train['depth'], kde = True, color = 'b', hist_kws={'alpha': 0.9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(train['table'], kde = True, color = 'b', hist_kws={'alpha': 0.9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(train['price'], kde = True, color = 'b', hist_kws={'alpha': 0.9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(train['x'], kde = True, color = 'b', hist_kws={'alpha': 0.9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(train['y'], kde = False, color = 'b', hist_kws={'alpha': 0.9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(train['z'], kde = False, color = 'b', hist_kws={'alpha': 0.9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#we look at box plots to understand the distributions\n",
    "train.boxplot(column='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.boxplot(column='price', by = 'clarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y', 'z'\n",
    "plt.figure(figsize = (12, 6))\n",
    "sns.boxplot(x = 'carat', y = 'price',  data = train)\n",
    "xt = plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "sns.boxplot(x = 'cut', y = 'price',  data = train)\n",
    "xt = plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "sns.boxplot(x = 'clarity', y = 'price',  data = train)\n",
    "xt = plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.boxplot(train_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Pair Plot\n",
    "plt.figure()\n",
    "sns.pairplot(data=train[['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y', 'z']],\n",
    "              dropna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.plot(train['carat'], train['price'],marker='o', linestyle='--', color='r',label='price')\n",
    "#plt.plot(train['YrSold'], train['SalePrice'],  label='Year Sold')\n",
    "plt.xlabel('Carat')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Price Vs Carat')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['volume'] = train.x * train.y * train.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.plot(kind=\"scatter\",     # Create a scatterplot\n",
    "              x=\"carat\",          # Put carat on the x axis\n",
    "              y=\"volume\",          # Put price on the y axis\n",
    "              figsize=(3,3),\n",
    "              ylim=(0,2000))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.plot(kind=\"scatter\",     # Create a scatterplot\n",
    "              x=\"volume\",          # Put carat on the x axis\n",
    "              y=\"price\",          # Put price on the y axis\n",
    "              figsize=(3,3),\n",
    "              ylim=(0,4000))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correlationMatrix = train_copy.corr().abs()\n",
    "\n",
    "plt.subplots(figsize=(13, 9))\n",
    "sns.heatmap(correlationMatrix,annot=True)\n",
    "\n",
    "# Mask unimportant features\n",
    "sns.heatmap(correlationMatrix, mask=correlationMatrix < 1, cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### It might be easier if you think of GROUP BY as \"for each\" for the sake of explanation. The query below:\n",
    "\n",
    "* SELECT empid, SUM (MonthlySalary) \n",
    "* FROM Employee\n",
    "* GROUP BY EmpID\n",
    "\n",
    "is saying:\n",
    "\n",
    "###### \"Give me the sum of MonthlySalary's for each empid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.shanelynn.ie/summarising-aggregation-and-grouping-data-in-python-pandas/\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the sum of the carats per price\n",
    "train.groupby('price')['carat'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the price in each carat\n",
    "train.groupby('carat')['price'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How much price, x are in each carat?\n",
    "train.groupby(['carat', 'x'])['price'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Group the data frame by price and carat and extract a number of stats from each group\n",
    "train.groupby(['price', 'carat']).agg({'table':sum,      # find the sum of the table for each group\n",
    "                                     'depth': \"count\", # find the number of depth type entries\n",
    "                                     'x': 'first'})    # get the first x per group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "f, axarr = plt.subplots(3, 2, figsize=(8, 6))\n",
    "price = train.price.values\n",
    "axarr[0, 0].scatter(train['carat'].values, price)\n",
    "axarr[0, 0].set_title('Carat')\n",
    "axarr[0, 1].scatter(train.depth.values, price)\n",
    "axarr[0, 1].set_title('Depth Percentage')\n",
    "axarr[1, 0].scatter(train.table.values, price)\n",
    "axarr[1, 0].set_title('Table')\n",
    "axarr[1, 1].scatter(train['x'].values, price)\n",
    "axarr[1, 1].set_title('Length')\n",
    "axarr[2, 0].scatter(train.y.values, price)\n",
    "axarr[2, 0].set_title('Width')\n",
    "axarr[2, 1].scatter(train.z.values, price)\n",
    "axarr[2, 1].set_title('Depth')\n",
    "f.text(-0.01, 0.5, 'Price', va='center', rotation='vertical', fontsize = 18)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select continous variable where z is not zero..\n",
    "#from now onward this is what we are going to use\n",
    "train = train_cont[ (train ['z'] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "f, axarr = plt.subplots(3, 2, figsize=(6, 5))\n",
    "price = train.price.values\n",
    "axarr[0, 0].scatter(train['carat'].values, price)\n",
    "axarr[0, 0].set_title('Carat')\n",
    "axarr[0, 1].scatter(train.depth.values, price)\n",
    "axarr[0, 1].set_title('Depth Percentage')\n",
    "axarr[1, 0].scatter(train.table.values, price)\n",
    "axarr[1, 0].set_title('Table')\n",
    "axarr[1, 1].scatter(train['x'].values, price)\n",
    "axarr[1, 1].set_title('Length')\n",
    "axarr[2, 0].scatter(train.y.values, price)\n",
    "axarr[2, 0].set_title('Width')\n",
    "axarr[2, 1].scatter(train.z.values, price)\n",
    "axarr[2, 1].set_title('Depth')\n",
    "f.text(-0.01, 0.5, 'Price', va='center', rotation='vertical', fontsize = 18)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reshape the train with price as the last column\n",
    "train_copy  = train[['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'x', 'y', 'z','price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr = train_copy.iloc[:, 0:].corr()\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(corr, vmax=1, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cor_dict = corr['price'].to_dict()\n",
    "del cor_dict['price']\n",
    "print(\"List the numerical features decendingly by their correlation with Price:\\n\")\n",
    "for ele in sorted(cor_dict.items(), key = lambda x: -abs(x[1])):\n",
    "    print(\"{0}: \\t{1}\".format(*ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correlationMatrix = train_copy.corr().abs()\n",
    "\n",
    "plt.subplots(figsize=(7, 5))\n",
    "sns.heatmap(correlationMatrix,annot=True)\n",
    "\n",
    "# Mask unimportant features\n",
    "sns.heatmap(correlationMatrix, mask=correlationMatrix < 1, cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A seaborn jointplot shows bivariate scatterplots and univariate histograms in the same figure\n",
    "ax = sns.jointplot(x=\"price\", y=\"carat\", data=train, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot data and a linear regression model fit.\n",
    "#Use a 68% confidence interval, which corresponds with the standard error of the estimate:\n",
    "ax = sns.regplot(x = 'price', y = 'carat', data = train_copy, color = 'Green',ci=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show value counts for a single categorical variable:\n",
    "ax = sns.countplot(x=\"cut\", data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show value counts for a single categorical variable:\n",
    "ax = sns.countplot(x=\"color\", data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"clarity\", data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(y=\"cut\", hue=\"color\", data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6, 4))\n",
    "sns.boxplot(x = 'cut', y = 'price',  data = train)\n",
    "xt = plt.xticks(rotation=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#3 way Anova along the price\n",
    "sns.factorplot('clarity', 'price', hue = 'color',col = 'cut', estimator = np.mean, data = train, \n",
    "             size = 3, aspect = .8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode some categorical features as ordered numbers when there is information in the order\n",
    "train = train.replace({\"cut\" : {\"Fair\" : 1, \"Good\" : 2, \"Very Good\" : 3, \"Premium\" : 4, \"Ideal\" : 5},\n",
    "                       \"color\" : {\"J\" : 7, \"I\" : 6, \"H\" : 5, \"G\" : 4, \"F\" : 3, \"E\" : 2, \"D\" : 1},\n",
    "                       \"clarity\" : {\"I1\" : 1, \"SI1\" : 2, \"SI2\": 3, \"VS1\" : 4, \"VS2\" : 5, \"VVS1\" : 6, \"VVS2\" : 7, \"IF\" : 8}}\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reshape the train with price as the last column\n",
    "train  = train[['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'x', 'y', 'z','price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#log transform the target:\n",
    "train[\"price\"] = np.log1p(train[\"price\"])\n",
    "train['log_carat'] = np.log1p(train['carat'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find most important features relative to target\n",
    "print(\"Find most important features relative to target\")\n",
    "corr = train.corr()\n",
    "corr.sort_values([\"price\"], ascending = False, inplace = True)\n",
    "print(corr.price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Separate into target variable and other variables\n",
    "train_m = train.drop(['price','x','y','z','carat'], axis=1)\n",
    "y = train.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_m.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Partition the dataset in train + validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_m, y, test_size = 0.3, random_state = 0)\n",
    "print(\"X_train : \" + str(X_train.shape))\n",
    "print(\"X_test : \" + str(X_test.shape))\n",
    "print(\"y_train : \" + str(y_train.shape))\n",
    "print(\"y_test : \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas R-squared is a relative measure of fit, RMSE is an absolute measure of fit. As the square root of a variance, RMSE can be interpreted as the standard deviation of the unexplained variance, and has the useful property of being in the same units as the response variable. Lower values of RMSE indicate better fit.\n",
    "\n",
    "http://www.theanalysisfactor.com/assessing-the-fit-of-regression-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define : RMSE\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better = False)\n",
    "\n",
    "def rmse_cv_train(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, y_train, scoring = scorer, cv = 10))\n",
    "    return(rmse)\n",
    "\n",
    "def rmse_cv_test(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_test, y_test, scoring = scorer, cv = 10))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Linear Regression without regularisation\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Look at predictions on training and validation set\n",
    "print(\"RMSE on Training set :\", rmse_cv_train(lr).mean())\n",
    "print(\"RMSE on Test set :\", rmse_cv_test(lr).mean())\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "# Plot residuals\n",
    "plt.scatter(y_train_pred, y_train_pred - y_train, c = \"blue\", marker = \"s\", label = \"Training data\")\n",
    "plt.scatter(y_test_pred, y_test_pred - y_test, c = \"lightgreen\", marker = \"s\", label = \"Validation data\")\n",
    "plt.title(\"Linear regression\")\n",
    "plt.xlabel(\"Predicted values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.hlines(y = 0, xmin = .5, xmax = 1, color = \"red\")\n",
    "plt.show()\n",
    "\n",
    "# Plot predictions\n",
    "plt.scatter(y_train_pred, y_train, c = \"blue\", marker = \"s\", label = \"Training data\")\n",
    "plt.scatter(y_test_pred, y_test, c = \"lightgreen\", marker = \"s\", label = \"Validation data\")\n",
    "plt.title(\"Linear regression\")\n",
    "plt.xlabel(\"Predicted values\")\n",
    "plt.ylabel(\"Real values\")\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.plot([.5, .9], [.5, .9], c = \"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Errors seem randomly distributed and randomly scattered around the centerline, so there is that at least. It means our model was able to capture most of the explanatory information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2* Ridge\n",
    "ridge = RidgeCV(alphas = [0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1, 3, 6, 10, 30, 60])\n",
    "ridge.fit(X_train, y_train)\n",
    "alpha = ridge.alpha_\n",
    "print(\"Best alpha :\", alpha)\n",
    "\n",
    "print(\"Try again for more precision with alphas centered around \" + str(alpha))\n",
    "ridge = RidgeCV(alphas = [alpha * .6, alpha * .65, alpha * .7, alpha * .75, alpha * .8, alpha * .85, \n",
    "                          alpha * .9, alpha * .95, alpha, alpha * 1.05, alpha * 1.1, alpha * 1.15,\n",
    "                          alpha * 1.25, alpha * 1.3, alpha * 1.35, alpha * 1.4], \n",
    "                cv = 10)\n",
    "ridge.fit(X_train, y_train)\n",
    "alpha = ridge.alpha_\n",
    "print(\"Best alpha :\", alpha)\n",
    "\n",
    "print(\"Ridge RMSE on Training set :\", rmse_cv_train(ridge).mean())\n",
    "print(\"Ridge RMSE on Test set :\", rmse_cv_test(ridge).mean())\n",
    "y_train_rdg = ridge.predict(X_train)\n",
    "y_test_rdg = ridge.predict(X_test)\n",
    "\n",
    "# Plot residuals\n",
    "plt.scatter(y_train_rdg, y_train_rdg - y_train, c = \"blue\", marker = \"s\", label = \"Training data\")\n",
    "plt.scatter(y_test_rdg, y_test_rdg - y_test, c = \"lightgreen\", marker = \"s\", label = \"Validation data\")\n",
    "plt.title(\"Linear regression with Ridge regularization\")\n",
    "plt.xlabel(\"Predicted values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.hlines(y = 0, xmin = 10.5, xmax = 13.5, color = \"red\")\n",
    "plt.show()\n",
    "\n",
    "# Plot predictions\n",
    "plt.scatter(y_train_rdg, y_train, c = \"blue\", marker = \"s\", label = \"Training data\")\n",
    "plt.scatter(y_test_rdg, y_test, c = \"lightgreen\", marker = \"s\", label = \"Validation data\")\n",
    "plt.title(\"Linear regression with Ridge regularization\")\n",
    "plt.xlabel(\"Predicted values\")\n",
    "plt.ylabel(\"Real values\")\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.plot([10.5, 13.5], [10.5, 13.5], c = \"red\")\n",
    "plt.show()\n",
    "\n",
    "# Plot important coefficients\n",
    "coefs = pd.Series(ridge.coef_, index = X_train.columns)\n",
    "print(\"Ridge picked \" + str(sum(coefs != 0)) + \" features and eliminated the other \" +  \\\n",
    "      str(sum(coefs == 0)) + \" features\")\n",
    "imp_coefs = pd.concat([coefs.sort_values().head(10),\n",
    "                     coefs.sort_values().tail(10)])\n",
    "imp_coefs.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients in the Ridge Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is very slight increase in RMSE result now that we've added regularization. The very small difference between training and test results indicate that we eliminated most of the overfitting. Visually, the graphs seem to confirm that idea.\n",
    "Ridge used all of the existing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3* Lasso\n",
    "lasso = LassoCV(alphas = [0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, \n",
    "                          0.3, 0.6, 1], \n",
    "                max_iter = 50000, cv = 10)\n",
    "lasso.fit(X_train, y_train)\n",
    "alpha = lasso.alpha_\n",
    "print(\"Best alpha :\", alpha)\n",
    "\n",
    "print(\"Try again for more precision with alphas centered around \" + str(alpha))\n",
    "lasso = LassoCV(alphas = [alpha * .6, alpha * .65, alpha * .7, alpha * .75, alpha * .8, \n",
    "                          alpha * .85, alpha * .9, alpha * .95, alpha, alpha * 1.05, \n",
    "                          alpha * 1.1, alpha * 1.15, alpha * 1.25, alpha * 1.3, alpha * 1.35, \n",
    "                          alpha * 1.4], \n",
    "                max_iter = 50000, cv = 10)\n",
    "lasso.fit(X_train, y_train)\n",
    "alpha = lasso.alpha_\n",
    "print(\"Best alpha :\", alpha)\n",
    "\n",
    "print(\"Lasso RMSE on Training set :\", rmse_cv_train(lasso).mean())\n",
    "print(\"Lasso RMSE on Test set :\", rmse_cv_test(lasso).mean())\n",
    "y_train_las = lasso.predict(X_train)\n",
    "y_test_las = lasso.predict(X_test)\n",
    "\n",
    "# Plot residuals\n",
    "plt.scatter(y_train_las, y_train_las - y_train, c = \"blue\", marker = \"s\", label = \"Training data\")\n",
    "plt.scatter(y_test_las, y_test_las - y_test, c = \"lightgreen\", marker = \"s\", label = \"Validation data\")\n",
    "plt.title(\"Linear regression with Lasso regularization\")\n",
    "plt.xlabel(\"Predicted values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.hlines(y = 0, xmin = 10.5, xmax = 13.5, color = \"red\")\n",
    "plt.show()\n",
    "\n",
    "# Plot predictions\n",
    "plt.scatter(y_train_las, y_train, c = \"blue\", marker = \"s\", label = \"Training data\")\n",
    "plt.scatter(y_test_las, y_test, c = \"lightgreen\", marker = \"s\", label = \"Validation data\")\n",
    "plt.title(\"Linear regression with Lasso regularization\")\n",
    "plt.xlabel(\"Predicted values\")\n",
    "plt.ylabel(\"Real values\")\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.plot([10.5, 13.5], [10.5, 13.5], c = \"red\")\n",
    "plt.show()\n",
    "\n",
    "# Plot important coefficients\n",
    "coefs = pd.Series(lasso.coef_, index = X_train.columns)\n",
    "print(\"Lasso picked \" + str(sum(coefs != 0)) + \" features and eliminated the other \" +  \\\n",
    "      str(sum(coefs == 0)) + \" features\")\n",
    "imp_coefs = pd.concat([coefs.sort_values().head(10),\n",
    "                     coefs.sort_values().tail(10)])\n",
    "imp_coefs.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients in the Lasso Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Again not much change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4* ElasticNet\n",
    "elasticNet = ElasticNetCV(l1_ratio = [0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95, 1],\n",
    "                          alphas = [0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, \n",
    "                                    0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1, 3, 6], \n",
    "                          max_iter = 50000, cv = 10)\n",
    "elasticNet.fit(X_train, y_train)\n",
    "alpha = elasticNet.alpha_\n",
    "ratio = elasticNet.l1_ratio_\n",
    "print(\"Best l1_ratio :\", ratio)\n",
    "print(\"Best alpha :\", alpha )\n",
    "\n",
    "print(\"Try again for more precision with l1_ratio centered around \" + str(ratio))\n",
    "elasticNet = ElasticNetCV(l1_ratio = [ratio * .85, ratio * .9, ratio * .95, ratio, ratio * 1.05, ratio * 1.1, ratio * 1.15],\n",
    "                          alphas = [0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1, 3, 6], \n",
    "                          max_iter = 50000, cv = 10)\n",
    "elasticNet.fit(X_train, y_train)\n",
    "if (elasticNet.l1_ratio_ > 1):\n",
    "    elasticNet.l1_ratio_ = 1    \n",
    "alpha = elasticNet.alpha_\n",
    "ratio = elasticNet.l1_ratio_\n",
    "print(\"Best l1_ratio :\", ratio)\n",
    "print(\"Best alpha :\", alpha )\n",
    "\n",
    "\n",
    "print(\"Now try again for more precision on alpha, with l1_ratio fixed at \" + str(ratio) + \n",
    "      \" and alpha centered around \" + str(alpha))\n",
    "elasticNet = ElasticNetCV(l1_ratio = ratio,\n",
    "                          alphas = [alpha * .6, alpha * .65, alpha * .7, alpha * .75, alpha * .8, alpha * .85, alpha * .9, \n",
    "                                    alpha * .95, alpha, alpha * 1.05, alpha * 1.1, alpha * 1.15, alpha * 1.25, alpha * 1.3, \n",
    "                                    alpha * 1.35, alpha * 1.4], \n",
    "                          max_iter = 50000, cv = 10)\n",
    "elasticNet.fit(X_train, y_train)\n",
    "if (elasticNet.l1_ratio_ > 1):\n",
    "    elasticNet.l1_ratio_ = 1    \n",
    "alpha = elasticNet.alpha_\n",
    "ratio = elasticNet.l1_ratio_\n",
    "print(\"Best l1_ratio :\", ratio)\n",
    "print(\"Best alpha :\", alpha )\n",
    "\n",
    "print(\"ElasticNet RMSE on Training set :\", rmse_cv_train(elasticNet).mean())\n",
    "print(\"ElasticNet RMSE on Test set :\", rmse_cv_test(elasticNet).mean())\n",
    "y_train_ela = elasticNet.predict(X_train)\n",
    "y_test_ela = elasticNet.predict(X_test)\n",
    "\n",
    "# Plot residuals\n",
    "plt.scatter(y_train_ela, y_train_ela - y_train, c = \"blue\", marker = \"s\", label = \"Training data\")\n",
    "plt.scatter(y_test_ela, y_test_ela - y_test, c = \"lightgreen\", marker = \"s\", label = \"Validation data\")\n",
    "plt.title(\"Linear regression with ElasticNet regularization\")\n",
    "plt.xlabel(\"Predicted values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.hlines(y = 0, xmin = 10.5, xmax = 13.5, color = \"red\")\n",
    "plt.show()\n",
    "\n",
    "# Plot predictions\n",
    "plt.scatter(y_train, y_train_ela, c = \"blue\", marker = \"s\", label = \"Training data\")\n",
    "plt.scatter(y_test, y_test_ela, c = \"lightgreen\", marker = \"s\", label = \"Validation data\")\n",
    "plt.title(\"Linear regression with ElasticNet regularization\")\n",
    "plt.xlabel(\"Predicted values\")\n",
    "plt.ylabel(\"Real values\")\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.plot([10.5, 13.5], [10.5, 13.5], c = \"red\")\n",
    "plt.show()\n",
    "\n",
    "# Plot important coefficients\n",
    "coefs = pd.Series(elasticNet.coef_, index = X_train.columns)\n",
    "print(\"ElasticNet picked \" + str(sum(coefs != 0)) + \" features and eliminated the other \" +  str(sum(coefs == 0)) + \" features\")\n",
    "imp_coefs = pd.concat([coefs.sort_values().head(10),\n",
    "                     coefs.sort_values().tail(10)])\n",
    "imp_coefs.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients in the ElasticNet Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Again not much change. Therefore Linear Regression is the best option to use in the situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
